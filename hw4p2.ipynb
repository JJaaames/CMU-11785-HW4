{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from options import *\n",
    "from Encoder import *\n",
    "from Decoder import *\n",
    "from util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Sucessful.....\n",
      "----------------- Options ---------------\n",
      "                 dataroot: ./data/                       \n",
      "       decoder_hidden_dim: 512                           \n",
      "       decoder_num_layers: 2                             \n",
      "                   device: cuda                          \n",
      "             display_freq: 10                            \n",
      "                  dropout: 0.5                           \n",
      "           embedding_size: 256                           \n",
      "       encoder_hidden_dim: 256                           \n",
      "       encoder_num_layers: 4                             \n",
      "                input_dim: 40                            \n",
      "         is_bidirectional: True                          \n",
      "                 key_size: 128                           \n",
      "                       lr: 0.001                         \n",
      "               model_name: LAS_latest                    \n",
      "                  n_epoch: 10                            \n",
      "         save_latest_freq: 3                             \n",
      "                      tao: 0.1                           \n",
      "    teacher_forcing_ratio: 0.9                           \n",
      "          test_batch_size: 256                           \n",
      "         train_batch_size: 64                            \n",
      "           val_batch_size: 256                           \n",
      "               value_size: 128                           \n",
      "               vocab_size: 17200                         \t[default: 34]\n",
      "----------------- End -------------------\n",
      "Transfer the transcript from words to index sucessfully.....\n",
      "Decoder(\n",
      "  (embedding): Embedding(17200, 256)\n",
      "  (attention): Attention(\n",
      "    (query_network): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (lstm1): LSTMCell(384, 512)\n",
      "  (key_network): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (value_network): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (character_prob): Linear(in_features=512, out_features=17200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "options = BaseOptions()\n",
    "opt = options.parser.parse_args(args = [])\n",
    "\n",
    "speech_train = np.load(opt.dataroot + 'train_new.npy', allow_pickle=True, encoding='bytes')\n",
    "speech_valid = np.load(opt.dataroot + 'dev_new.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "transcript_train = np.load(opt.dataroot + 'train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "transcript_valid = np.load(opt.dataroot + 'dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "print(\"Data Loading Sucessful.....\")\n",
    "\n",
    "word_dict, word_list, transcript_train, transcript_valid = collect_word(transcript_train, transcript_valid)\n",
    "opt.vocab_size = len(word_list)\n",
    "options.printer(opt)\n",
    "print(\"Transfer the transcript from words to index sucessfully.....\")\n",
    "\n",
    "encoder = Encoder(opt)\n",
    "decoder = Decoder(opt)\n",
    "# encoder.load_state_dict(torch.load('./pre_train_model/encoder_pretrained.pt'))\n",
    "# decoder.load_state_dict(torch.load('./pre_train_model/decoder_pretrained.pt'))\n",
    "encoder.to(opt.device)\n",
    "decoder.to(opt.device)\n",
    "print(decoder)\n",
    "optimizer_encoder = Adam(encoder.parameters(), opt.lr, weight_decay = 1e-6)\n",
    "optimizer_decoder = Adam(decoder.parameters(), opt.lr, weight_decay = 1e-6)\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "criterion.to(opt.device)\n",
    "\n",
    "\n",
    "train_data = MyDataset(speech_train, transcript_train)\n",
    "dev_data = MyDataset(speech_valid, transcript_valid)\n",
    "\n",
    "train_loader_args = dict(batch_size = opt.train_batch_size, pin_memory=True, shuffle = True, collate_fn = collate_fn) \n",
    "train_loader = Data.DataLoader(train_data, **train_loader_args)\n",
    "dev_loader_args = dict(shuffle=False, batch_size = opt.val_batch_size, pin_memory=True, collate_fn = collate_fn) \n",
    "dev_loader = Data.DataLoader(dev_data, **dev_loader_args)\n",
    "\n",
    "# training(opt, encoder, decoder, train_loader, dev_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (utterances, labels, u_lens, l_lens) in enumerate(dev_loader):\n",
    "    utterances = utterances.permute(1, 0, 2)\n",
    "    utterances = utterances.to(opt.device)\n",
    "    labels = labels.to(opt.device)\n",
    "    u_lens = u_lens.to(opt.device)\n",
    "    l_lens = l_lens.to(opt.device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2516, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1106 - 256 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list.append('wtf???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = np.array(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DOUBLE-QUOTE', \"HAVEN'T\", 'WE', 'ALREADY', 'GONE', 'wtf???', 'IN',\n",
       "       'S.', 'B.', 'A.', 'BUDGET', 'CUTS', 'QUESTION-MARK',\n",
       "       'DOUBLE-QUOTE', '<eos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
       "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>', '<sos>',\n",
       "       '<sos>', '<sos>', '<sos>', '<sos>', '<sos>'], dtype='<U18')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[labels[81].detach().cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'DOUBLE-QUOTE', b\"HAVEN'T\", b'WE', b'ALREADY', b'GONE',\n",
       "       b'OVERBOARD', b'IN', b'S.', b'B.', b'A.', b'BUDGET', b'CUTS',\n",
       "       b'QUESTION-MARK', b'DOUBLE-QUOTE'], dtype='|S13')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(opt.dataroot + 'dev_transcripts.npy', allow_pickle=True,encoding='bytes')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17199"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict['OVERBOARD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOUBLE-QUOTE'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict['PROPOSED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Sucessful.....\n",
      "Transfer the transcript from letters to index sucessfully.....\n"
     ]
    }
   ],
   "source": [
    "options = BaseOptions()\n",
    "opt = options.parser.parse_args(args = [])\n",
    "# options.printer(opt)\n",
    "speech_train = np.load(opt.dataroot + 'train_new.npy', allow_pickle=True, encoding='bytes')\n",
    "speech_valid = np.load(opt.dataroot + 'dev_new.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "transcript_train = np.load(opt.dataroot + 'train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "transcript_valid = np.load(opt.dataroot + 'dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "print(\"Data Loading Sucessful.....\")\n",
    "encoder = Encoder(opt)\n",
    "decoder = Decoder(opt)\n",
    "encoder.to(opt.device)\n",
    "decoder.to(opt.device)\n",
    "# optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), opt.lr)\n",
    "# criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "# criterion.to(opt.device)\n",
    "\n",
    "transcript_train = transform_letter_to_index(transcript_train)\n",
    "transcript_valid = transform_letter_to_index(transcript_valid)\n",
    "\n",
    "print(\"Transfer the transcript from letters to index sucessfully.....\")\n",
    "train_data = MyDataset(speech_train, transcript_train)\n",
    "dev_data = MyDataset(speech_valid, transcript_valid)\n",
    "\n",
    "train_loader_args = dict(batch_size = opt.train_batch_size, pin_memory=True, shuffle = True, collate_fn = collate_fn) \n",
    "train_loader = Data.DataLoader(train_data, **train_loader_args)\n",
    "dev_loader_args = dict(shuffle=False, batch_size = opt.val_batch_size, pin_memory=True, collate_fn = collate_fn) \n",
    "dev_loader = Data.DataLoader(dev_data, **dev_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.encoder_num_layers = 3\n",
    "# encoder = Encoder(opt)\n",
    "# decoder = Decoder(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.train_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('./LAS_latest/encoder_latest.pt'))\n",
    "decoder.load_state_dict(torch.load('./LAS_latest/decoder_latest.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_args = dict(batch_size = opt.train_batch_size, pin_memory=True, shuffle = True, collate_fn = collate_fn) \n",
    "train_loader = Data.DataLoader(train_data, **train_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (blstm): ModuleList(\n",
       "    (0): LSTM(40, 256, bias=False, bidirectional=True)\n",
       "    (1): LSTM(512, 256, bias=False, bidirectional=True)\n",
       "    (2): LSTM(512, 256, bias=False, bidirectional=True)\n",
       "    (3): LSTM(512, 256, bias=False, bidirectional=True)\n",
       "  )\n",
       "  (pooling): ModuleList(\n",
       "    (0): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    (2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  )\n",
       "  (dropout): LockedDropout()\n",
       "  (key_network): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (value_network): Linear(in_features=512, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(34, 256)\n",
       "  (attention): Attention(\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (lstm1): LSTMCell(384, 512)\n",
       "  (lstm2): LSTMCell(512, 128)\n",
       "  (character_prob): Linear(in_features=256, out_features=34, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (utterances, labels, u_lens, l_lens) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = utterances.permute(1, 0, 2)\n",
    "utterances = utterances.to(opt.device)\n",
    "labels = labels.to(opt.device)\n",
    "u_lens = u_lens.to(opt.device)\n",
    "l_lens = l_lens.to(opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(34, 256)\n",
       "  (attention): Attention(\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (lstm1): LSTMCell(384, 512)\n",
       "  (lstm2): LSTMCell(512, 128)\n",
       "  (character_prob): Linear(in_features=256, out_features=34, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.cuda()\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values, out_lens = encoder(utterances, u_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = keys.permute(1, 0, 2)\n",
    "values = values.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.zeros(labels.size(0), 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed = decoder.embedding(prediction.argmax()).cuda().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed = decoder.embedding(prediction.argmax()).cuda().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, atten = decoder.attention(keys, char_embed, values, out_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.cat([char_embed, context], dim=1)\n",
    "hidden_states[0] = decoder.lstm1(inp, hidden_states[0])\n",
    "\n",
    "inp_2 = hidden_states[0][0]\n",
    "hidden_states[1] = decoder.lstm2(inp_2,hidden_states[1])\n",
    "\n",
    "output = hidden_states[1][0]\n",
    "prediction = decoder.character_prob(torch.cat([output, context], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9355,  1.8090,  1.5464,  0.5434,  1.3102,  0.3379,  0.6489, -0.6706,\n",
       "          1.5793,  1.9630, -0.7702, -1.9915, -0.0747,  1.8338,  0.2829,  0.5961,\n",
       "          0.4211, -1.3401, -0.3865,  1.3588,  3.0147, -0.6365, -1.1750,  1.2666,\n",
       "         -2.2012, -1.0429, -3.1345, -2.9072, -3.1234, -2.3456, -4.7030, -3.9961,\n",
       "         -1.6158, -2.6410]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20,  8,  5, 32, 19,  5,  3, 21, 18,  9, 20,  9,  5, 19, 32,  1, 14,  4,\n",
       "         32,  5, 24,  3,  8,  1, 14,  7,  5, 32,  3, 15, 13, 13,  9, 19, 19,  9,\n",
       "         15, 14, 32, 19,  1,  9,  4, 32, 23,  5,  4, 14,  5, 19,  4,  1, 25, 32,\n",
       "         20,  8,  1, 20, 32, 16,  5, 14, 14, 26, 15,  9, 12, 28, 19, 32, 13,  5,\n",
       "         18,  7,  5, 18, 32, 16,  1,  3, 20, 32, 23,  9, 20,  8, 32,  7,  5, 20,\n",
       "         20, 25, 32, 15,  9, 12, 32, 22,  9, 15, 12,  1, 20,  5,  4, 32, 19,  5,\n",
       "          3, 21, 18,  9, 20,  9,  5, 19, 32, 12,  1, 23, 32,  3, 15, 13, 13,  1,\n",
       "         32,  4,  5,  1, 12,  9, 14,  7, 32,  1, 32,  2, 12, 15, 23, 32, 20, 15,\n",
       "         32,  9, 20, 19, 32, 12,  5,  7,  1, 12, 32,  3,  1, 19,  5, 32,  1,  7,\n",
       "          1,  9, 14, 19, 20, 32, 20,  5, 24,  1,  3, 15, 32, 16,  5, 18,  9, 15,\n",
       "          4, 32, 33]], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4813e-01, -1.3363e-01,  6.2932e-02, -5.4767e-02,  3.2711e-02,\n",
       "         -1.5171e-01, -5.6041e-02, -2.6125e-02,  3.1641e-02, -3.0940e-02,\n",
       "         -5.4296e-02, -7.4529e-02, -5.1847e-02, -6.0010e-02,  4.0519e-02,\n",
       "         -1.1589e-01, -3.9520e-02, -5.2895e-02, -4.9776e-02,  1.6528e-02,\n",
       "         -1.0221e-01,  1.6935e-02,  7.7424e-02,  1.0448e-01,  1.5855e-02,\n",
       "          2.3621e-02,  2.3680e-02, -1.0760e-02, -1.7462e-02, -9.5320e-02,\n",
       "         -5.9259e-02,  1.1899e-03, -2.2156e-02, -1.2748e-01, -8.3798e-02,\n",
       "          4.2732e-02,  1.0166e-01,  9.1426e-02, -6.3400e-02,  1.2062e-01,\n",
       "         -4.0561e-02, -5.6035e-02, -1.2139e-02,  1.8392e-02,  1.1864e-02,\n",
       "          5.4278e-02,  9.8208e-02,  6.6086e-02, -7.4572e-03,  7.5491e-03,\n",
       "         -4.5364e-02, -7.8733e-02,  3.1196e-02,  6.2914e-02, -7.7238e-02,\n",
       "          1.5153e-01, -3.7419e-02,  1.8120e-02, -1.3286e-01, -1.2729e-01,\n",
       "         -1.3567e-02,  2.7741e-02, -1.4475e-01,  1.5018e-02, -1.0957e-01,\n",
       "          5.2601e-02,  3.6138e-03, -8.8516e-02,  7.5944e-02,  1.8512e-01,\n",
       "          3.2528e-02,  1.6613e-02, -7.3476e-02, -1.1416e-02,  4.9228e-02,\n",
       "          4.6365e-02,  4.3687e-02,  8.4480e-02, -6.7074e-02, -2.7335e-02,\n",
       "          5.7791e-02,  2.0558e-02, -5.5857e-02,  6.5084e-02,  8.3479e-02,\n",
       "         -3.6378e-02, -5.7513e-02, -9.3942e-02, -1.2290e-01, -1.9696e-02,\n",
       "          6.6011e-02, -2.7217e-02, -1.3694e-01,  1.0033e-01,  4.6357e-02,\n",
       "          9.9129e-02,  6.3569e-02,  3.5858e-02, -1.5133e-02,  4.8562e-03,\n",
       "         -1.4823e-01,  1.4300e-02,  5.5822e-02,  2.9244e-02,  8.8346e-02,\n",
       "         -1.7271e-01,  2.7122e-02,  1.6403e-02, -5.6430e-02,  2.3011e-02,\n",
       "          1.5066e-01,  1.2550e-01, -7.7298e-02,  2.0173e-03, -2.6924e-02,\n",
       "          4.1293e-02,  8.8815e-02, -6.4113e-02, -8.3474e-02,  9.3684e-03,\n",
       "          9.9077e-02,  9.6674e-02, -3.3841e-02,  1.2561e-01, -3.1419e-02,\n",
       "         -1.0409e-01,  1.2335e-01, -9.3317e-02, -8.1265e-02,  6.7253e-02,\n",
       "          6.2209e-02,  3.7610e-02,  3.5047e-02,  3.1587e-04, -4.3561e-02,\n",
       "         -6.2153e-02,  1.7071e-01,  6.6374e-02,  1.0616e-01,  3.8013e-02,\n",
       "          2.9798e-02, -4.9250e-02,  3.2232e-03, -6.9589e-02,  6.6880e-02,\n",
       "         -8.1993e-03,  3.1199e-02, -1.4486e-01,  7.3730e-02, -3.2610e-02,\n",
       "          9.4457e-02, -3.3788e-02, -8.9837e-02,  7.6559e-02,  3.8336e-02,\n",
       "         -1.2647e-01,  1.3343e-01, -4.9766e-02,  7.7703e-02,  1.9022e-02,\n",
       "         -1.1743e-02,  6.7766e-02,  1.1962e-01, -1.1933e-01,  1.3806e-01,\n",
       "         -4.1006e-02,  1.8228e-03, -1.3848e-01, -5.4575e-02,  1.8755e-02,\n",
       "          6.8386e-02,  1.0674e-01,  1.2960e-02,  1.0178e-01,  7.6337e-02,\n",
       "          1.1994e-01,  6.6933e-03,  9.4558e-02,  1.6246e-01,  6.2062e-02,\n",
       "         -1.1603e-01, -3.4975e-02, -1.3360e-01,  7.9036e-02, -3.6599e-03,\n",
       "          5.9731e-02,  1.4905e-02, -6.0563e-03,  8.0429e-02, -2.8149e-02,\n",
       "         -7.7792e-02,  3.3260e-02,  4.4039e-02, -1.3033e-01, -3.1754e-02,\n",
       "         -1.3318e-01,  8.7489e-02,  6.5791e-02, -5.5831e-02, -2.8420e-02,\n",
       "          1.6161e-02, -1.4548e-02,  6.6847e-02,  3.3546e-02, -8.5990e-02,\n",
       "         -5.8989e-02, -2.4059e-03, -4.2667e-02, -9.9658e-02,  9.1800e-02,\n",
       "          4.2394e-02, -8.0950e-02, -7.5575e-02,  1.2608e-04,  5.6152e-02,\n",
       "          1.1802e-01,  9.0890e-02,  3.1853e-02, -4.9315e-02, -5.5558e-02,\n",
       "          3.7657e-02,  1.1515e-01,  3.3416e-02, -5.0218e-02,  8.4468e-02,\n",
       "          8.6331e-02,  4.6606e-02,  3.5053e-02,  7.8389e-02, -2.2694e-02,\n",
       "         -1.5869e-02, -9.3975e-02, -1.3127e-03, -3.9149e-02,  1.3334e-01,\n",
       "          4.9422e-02, -1.0565e-01, -1.7611e-02, -2.7295e-03, -1.1965e-01,\n",
       "         -9.0302e-02, -5.1484e-02, -5.3410e-03, -4.1197e-02, -5.7586e-02,\n",
       "         -8.1582e-02, -1.4815e-01,  8.5304e-02,  7.5313e-02, -4.2058e-02,\n",
       "         -1.0043e-01,  7.0053e-02,  4.2577e-03, -1.2528e-01, -1.9757e-02,\n",
       "          6.0437e-02]], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.embedding(labels)[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4813e-01, -1.3363e-01,  6.2932e-02, -5.4767e-02,  3.2711e-02,\n",
       "         -1.5171e-01, -5.6041e-02, -2.6125e-02,  3.1641e-02, -3.0940e-02,\n",
       "         -5.4296e-02, -7.4529e-02, -5.1847e-02, -6.0010e-02,  4.0519e-02,\n",
       "         -1.1589e-01, -3.9520e-02, -5.2895e-02, -4.9776e-02,  1.6528e-02,\n",
       "         -1.0221e-01,  1.6935e-02,  7.7424e-02,  1.0448e-01,  1.5855e-02,\n",
       "          2.3621e-02,  2.3680e-02, -1.0760e-02, -1.7462e-02, -9.5320e-02,\n",
       "         -5.9259e-02,  1.1899e-03, -2.2156e-02, -1.2748e-01, -8.3798e-02,\n",
       "          4.2732e-02,  1.0166e-01,  9.1426e-02, -6.3400e-02,  1.2062e-01,\n",
       "         -4.0561e-02, -5.6035e-02, -1.2139e-02,  1.8392e-02,  1.1864e-02,\n",
       "          5.4278e-02,  9.8208e-02,  6.6086e-02, -7.4572e-03,  7.5491e-03,\n",
       "         -4.5364e-02, -7.8733e-02,  3.1196e-02,  6.2914e-02, -7.7238e-02,\n",
       "          1.5153e-01, -3.7419e-02,  1.8120e-02, -1.3286e-01, -1.2729e-01,\n",
       "         -1.3567e-02,  2.7741e-02, -1.4475e-01,  1.5018e-02, -1.0957e-01,\n",
       "          5.2601e-02,  3.6138e-03, -8.8516e-02,  7.5944e-02,  1.8512e-01,\n",
       "          3.2528e-02,  1.6613e-02, -7.3476e-02, -1.1416e-02,  4.9228e-02,\n",
       "          4.6365e-02,  4.3687e-02,  8.4480e-02, -6.7074e-02, -2.7335e-02,\n",
       "          5.7791e-02,  2.0558e-02, -5.5857e-02,  6.5084e-02,  8.3479e-02,\n",
       "         -3.6378e-02, -5.7513e-02, -9.3942e-02, -1.2290e-01, -1.9696e-02,\n",
       "          6.6011e-02, -2.7217e-02, -1.3694e-01,  1.0033e-01,  4.6357e-02,\n",
       "          9.9129e-02,  6.3569e-02,  3.5858e-02, -1.5133e-02,  4.8562e-03,\n",
       "         -1.4823e-01,  1.4300e-02,  5.5822e-02,  2.9244e-02,  8.8346e-02,\n",
       "         -1.7271e-01,  2.7122e-02,  1.6403e-02, -5.6430e-02,  2.3011e-02,\n",
       "          1.5066e-01,  1.2550e-01, -7.7298e-02,  2.0173e-03, -2.6924e-02,\n",
       "          4.1293e-02,  8.8815e-02, -6.4113e-02, -8.3474e-02,  9.3684e-03,\n",
       "          9.9077e-02,  9.6674e-02, -3.3841e-02,  1.2561e-01, -3.1419e-02,\n",
       "         -1.0409e-01,  1.2335e-01, -9.3317e-02, -8.1265e-02,  6.7253e-02,\n",
       "          6.2209e-02,  3.7610e-02,  3.5047e-02,  3.1587e-04, -4.3561e-02,\n",
       "         -6.2153e-02,  1.7071e-01,  6.6374e-02,  1.0616e-01,  3.8013e-02,\n",
       "          2.9798e-02, -4.9250e-02,  3.2232e-03, -6.9589e-02,  6.6880e-02,\n",
       "         -8.1993e-03,  3.1199e-02, -1.4486e-01,  7.3730e-02, -3.2610e-02,\n",
       "          9.4457e-02, -3.3788e-02, -8.9837e-02,  7.6559e-02,  3.8336e-02,\n",
       "         -1.2647e-01,  1.3343e-01, -4.9766e-02,  7.7703e-02,  1.9022e-02,\n",
       "         -1.1743e-02,  6.7766e-02,  1.1962e-01, -1.1933e-01,  1.3806e-01,\n",
       "         -4.1006e-02,  1.8228e-03, -1.3848e-01, -5.4575e-02,  1.8755e-02,\n",
       "          6.8386e-02,  1.0674e-01,  1.2960e-02,  1.0178e-01,  7.6337e-02,\n",
       "          1.1994e-01,  6.6933e-03,  9.4558e-02,  1.6246e-01,  6.2062e-02,\n",
       "         -1.1603e-01, -3.4975e-02, -1.3360e-01,  7.9036e-02, -3.6599e-03,\n",
       "          5.9731e-02,  1.4905e-02, -6.0563e-03,  8.0429e-02, -2.8149e-02,\n",
       "         -7.7792e-02,  3.3260e-02,  4.4039e-02, -1.3033e-01, -3.1754e-02,\n",
       "         -1.3318e-01,  8.7489e-02,  6.5791e-02, -5.5831e-02, -2.8420e-02,\n",
       "          1.6161e-02, -1.4548e-02,  6.6847e-02,  3.3546e-02, -8.5990e-02,\n",
       "         -5.8989e-02, -2.4059e-03, -4.2667e-02, -9.9658e-02,  9.1800e-02,\n",
       "          4.2394e-02, -8.0950e-02, -7.5575e-02,  1.2608e-04,  5.6152e-02,\n",
       "          1.1802e-01,  9.0890e-02,  3.1853e-02, -4.9315e-02, -5.5558e-02,\n",
       "          3.7657e-02,  1.1515e-01,  3.3416e-02, -5.0218e-02,  8.4468e-02,\n",
       "          8.6331e-02,  4.6606e-02,  3.5053e-02,  7.8389e-02, -2.2694e-02,\n",
       "         -1.5869e-02, -9.3975e-02, -1.3127e-03, -3.9149e-02,  1.3334e-01,\n",
       "          4.9422e-02, -1.0565e-01, -1.7611e-02, -2.7295e-03, -1.1965e-01,\n",
       "         -9.0302e-02, -5.1484e-02, -5.3410e-03, -4.1197e-02, -5.7586e-02,\n",
       "         -8.1582e-02, -1.4815e-01,  8.5304e-02,  7.5313e-02, -4.2058e-02,\n",
       "         -1.0043e-01,  7.0053e-02,  4.2577e-03, -1.2528e-01, -1.9757e-02,\n",
       "          6.0437e-02]], device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.embedding(prediction.argmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                 dataroot: ./data/                       \n",
      "       decoder_hidden_dim: 512                           \n",
      "       decoder_num_layers: 2                             \n",
      "                   device: cuda                          \n",
      "             display_freq: 10                            \n",
      "                  dropout: 0.5                           \n",
      "           embedding_size: 256                           \n",
      "       encoder_hidden_dim: 256                           \n",
      "       encoder_num_layers: 4                             \n",
      "                input_dim: 40                            \n",
      "         is_bidirectional: True                          \n",
      "                 key_size: 128                           \n",
      "                       lr: 0.001                         \n",
      "               model_name: base_model                    \t[default: LAS_latest]\n",
      "                  n_epoch: 10                            \n",
      "         save_latest_freq: 3                             \n",
      "                      tao: 0.1                           \n",
      "    teacher_forcing_ratio: 0.9                           \n",
      "          test_batch_size: 256                           \n",
      "         train_batch_size: 64                            \n",
      "           val_batch_size: 256                           \n",
      "               value_size: 128                           \n",
      "               vocab_size: 34                            \n",
      "----------------- End -------------------\n",
      "Data Loading Sucessful.....\n",
      "SimpleDecoder(\n",
      "  (embed): Embedding(34, 256)\n",
      "  (lstm): LSTMCell(256, 512)\n",
      "  (fc): Linear(in_features=512, out_features=34, bias=True)\n",
      ")\n",
      "Transfer the transcript from letters to index sucessfully.....\n",
      "206.29475587703436\n",
      "205.64466546112115\n",
      "205.12839059674502\n",
      "201.69258589511753\n",
      "195.8218806509946\n",
      "142.4511754068716\n",
      "156.56600361663652\n",
      "94.46654611211574\n",
      "80.20976491862568\n",
      "110.66998191681736\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from options import *\n",
    "from Encoder import *\n",
    "from Decoder import *\n",
    "from util import *\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "def training(opt, encoder, decoder, train_loader, val_loader):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for epoch in range(opt.n_epoch):\n",
    "        avg_loss = 0\n",
    "        start = time.time()\n",
    "        for batch_idx, (utterances, labels, u_lens, l_lens) in enumerate(train_loader):\n",
    "            utterances = utterances.permute(1, 0, 2)\n",
    "            utterances = utterances.to(opt.device)\n",
    "            labels = labels.to(opt.device)\n",
    "            u_lens = u_lens.to(opt.device)\n",
    "            l_lens = l_lens.to(opt.device)\n",
    "            \n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "\n",
    "            outputs, hidden = encoder(utterances, u_lens)\n",
    "            hidden = (hidden[0].permute(1, 0, 2), hidden[1].permute(1, 0, 2))\n",
    "            hidden = (hidden[0].reshape(hidden[0].size(0), -1), hidden[1].reshape(hidden[1].size(0), -1))\n",
    "\n",
    "            predict_labels = decoder(hidden, labels)\n",
    "            predict_labels = predict_labels.permute(0, 2, 1)\n",
    "            loss = criterion(predict_labels, labels)\n",
    "            mask = torch.arange(labels.size(1)).unsqueeze(0).to(opt.device) >= l_lens.unsqueeze(1)\n",
    "            loss.masked_fill_(mask, 0.0)\n",
    "            loss = loss.sum() / l_lens.sum()\n",
    "            avg_loss += torch.exp(loss).item()\n",
    "            loss.backward()\n",
    "\n",
    "\t\t\t# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(encoder.parameters(), 0.25)   \n",
    "            nn.utils.clip_grad_norm_(decoder.parameters(), 0.25)   \n",
    "\n",
    "            if batch_idx % opt.display_freq == (opt.display_freq - 1):\n",
    "                file_name = os.path.join('./' + opt.model_name, '{}.txt'.format(opt.model_name))\n",
    "                with open(file_name, 'a') as opt_file:\n",
    "                    opt_file.write('batch = {}, Perplexity = {}, Running time = {}'.format(batch_idx + 1, avg_loss / opt.display_freq, time.time() - start))\n",
    "                    opt_file.write('\\n')\n",
    "                avg_loss = 0\n",
    "\n",
    "            if batch_idx % (opt.display_freq * 10) == (opt.display_freq * 10 - 1):\n",
    "                tmp_pred = transform_index_to_letter(predict_labels.unsqueeze(0))[0]\n",
    "                tmp_true = np.array(letter_list)[labels[0].detach().cpu().numpy()]\n",
    "                file_name_pred_train = os.path.join('./' + opt.model_name, '{}_pred_train.txt'.format(opt.model_name))\n",
    "                with open(file_name_pred_train, 'a') as opt_file:\n",
    "                    opt_file.write('prediction = {} Ground truth = {}'.format(tmp_pred, tmp_true))\n",
    "                    opt_file.write('\\n')\n",
    "                \n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "\n",
    "        validation(opt, encoder, decoder, val_loader)\n",
    "\n",
    "def validation(opt, encoder, decoder, val_loader):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    start = time.time()\n",
    "    running_loss = 0\n",
    "    total_seq = 0\n",
    "    score = 0\n",
    "    for batch_idx, (utterances, labels, u_lens, l_lens) in enumerate(val_loader):\n",
    "        utterances = utterances.permute(1, 0, 2)\n",
    "        utterances = utterances.to(opt.device)\n",
    "        labels = labels.to(opt.device)\n",
    "        u_lens = u_lens.to(opt.device)\n",
    "        l_lens = l_lens.to(opt.device)\n",
    "\n",
    "        outputs, hidden = encoder(utterances, u_lens)\n",
    "        hidden = (hidden[0].permute(1, 0, 2), hidden[1].permute(1, 0, 2))\n",
    "        hidden = (hidden[0].reshape(hidden[0].size(0), -1), hidden[1].reshape(hidden[1].size(0), -1))\n",
    "\n",
    "        predict_labels = decoder(hidden, labels)\n",
    "        predict_labels = predict_labels.permute(0, 2, 1)\n",
    "        loss = criterion(predict_labels, labels)\n",
    "        mask = torch.arange(labels.size(1)).unsqueeze(0).to(opt.device) >= l_lens.unsqueeze(1)\n",
    "        loss.masked_fill_(mask, 0.0)\n",
    "        loss = loss.sum() / l_lens.sum()\n",
    "        running_loss += torch.exp(loss).item()\n",
    "\n",
    "        predict_labels = predict_labels.permute(0, 2, 1)\n",
    "        for i in range(len(labels)):\n",
    "            true_sentence = ''\n",
    "            for j in range(l_lens[i] - 1):\n",
    "                true_sentence += letter_list[labels[i][j]]\n",
    "\n",
    "            predict_sentence = ''\n",
    "            for j in range(len(predict_labels[i])):\n",
    "                if predict_labels[i][j].argmax() == 33:\n",
    "                    break\n",
    "                predict_sentence += letter_list[predict_labels[i][j].argmax()]\n",
    "\n",
    "            score += levenshtein_distance(true_sentence, predict_sentence)\n",
    "            total_seq += 1\n",
    "\n",
    "    print(score / total_seq)\n",
    "    \n",
    "    file_name = os.path.join('./' + opt.model_name, '{}.txt'.format(opt.model_name))\n",
    "    with open(file_name, 'a') as opt_file:\n",
    "        opt_file.write('='*16)\n",
    "        opt_file.write('\\n')\n",
    "        opt_file.write('Perplexity = {}, Running time = {}'.format(running_loss / batch_idx, time.time() - start))\n",
    "        opt_file.write('\\n')\n",
    "    \n",
    "    predict_labels = predict_labels.permute(0, 2, 1)\n",
    "    tmp_pred = transform_index_to_letter(predict_labels.unsqueeze(0))[0]\n",
    "    tmp_true = np.array(letter_list)[labels[0].detach().cpu().numpy()]\n",
    "    file_name_pred_val = os.path.join('./' + opt.model_name, '{}_pred_val.txt'.format(opt.model_name))\n",
    "    with open(file_name_pred_val, 'a') as opt_file:\n",
    "        opt_file.write('true = {}, predict = {}'.format(tmp_pred, tmp_true))\n",
    "        opt_file.write('\\n')\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "options = BaseOptions()\n",
    "opt = options.parser.parse_args(args = [])\n",
    "opt.model_name = 'base_model'\n",
    "options.printer(opt)\n",
    "speech_train = np.load(opt.dataroot + 'train_new.npy', allow_pickle=True, encoding='bytes')\n",
    "speech_valid = np.load(opt.dataroot + 'dev_new.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "transcript_train = np.load(opt.dataroot + 'train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "transcript_valid = np.load(opt.dataroot + 'dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "print(\"Data Loading Sucessful.....\")\n",
    "encoder = SimpleEncoder(opt)\n",
    "decoder = SimpleDecoder(opt)\n",
    "encoder.to(opt.device)\n",
    "decoder.to(opt.device)\n",
    "print(decoder)\n",
    "optimizer_encoder = Adam(encoder.parameters(), opt.lr, weight_decay = 1e-6)\n",
    "optimizer_decoder = Adam(decoder.parameters(), opt.lr, weight_decay = 1e-6)\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none')\n",
    "criterion.to(opt.device)\n",
    "\n",
    "transcript_train = transform_letter_to_index(transcript_train)\n",
    "transcript_valid = transform_letter_to_index(transcript_valid)\n",
    "\n",
    "print(\"Transfer the transcript from letters to index sucessfully.....\")\n",
    "train_data = MyDataset(speech_train, transcript_train)\n",
    "dev_data = MyDataset(speech_valid, transcript_valid)\n",
    "\n",
    "train_loader_args = dict(batch_size = opt.train_batch_size, pin_memory=True, shuffle = True, collate_fn = collate_fn) \n",
    "train_loader = Data.DataLoader(train_data, **train_loader_args)\n",
    "dev_loader_args = dict(shuffle=False, batch_size = opt.val_batch_size, pin_memory=True, collate_fn = collate_fn) \n",
    "dev_loader = Data.DataLoader(dev_data, **dev_loader_args)\n",
    "\n",
    "training(opt, encoder, decoder, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Variable(torch.ones((10))).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
